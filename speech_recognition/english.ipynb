{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7975e779974748df9ba026b559a90eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Record', icon='microphone', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb6878811c44b6f837214de88c360a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Stop', icon='Stop_button', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b49a2a7985a41f7bf4eccda8ca70cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING: reverting to cpu as cuda is not available\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widget\n",
    "from IPython.display import display\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "\n",
    "messages = Queue()\n",
    "recording = Queue()\n",
    "# Threads are concepts (function) in python that runs in the background without distrubing the main function.\n",
    "# Queue will let us pass messeges between threads\n",
    "\n",
    "record_button = widget.Button(\n",
    "    description = \"Record\",\n",
    "    disabled= False,\n",
    "    Button_style = 'sucess',\n",
    "    icon = \"microphone\")\n",
    "\n",
    "Stop_button = widget.Button(\n",
    "    description = \"Stop\",\n",
    "    disabled = False,\n",
    "    button_style = 'Warning',\n",
    "    icon = 'Stop_button'\n",
    ")\n",
    "output = widget.Output()\n",
    "\n",
    "\n",
    "\n",
    "#in this function when the button is pressed we put data on the queue.\n",
    "def start_recording(data):\n",
    "    messages.put(True) # Message theat tells the threads what to do \n",
    "\n",
    "    with output:\n",
    "        display(\"start recording ..\")\n",
    "        record = Thread(target=record_microphone)\n",
    "        record.start()\n",
    "        speech = Thread(target=speech_recognitions,args=(output,))\n",
    "        speech.start()\n",
    "        \n",
    "        \n",
    " # This function when we press the button takes the message off the queue and the recoring will stop        \n",
    "def stop_recording(data):\n",
    "    with output:\n",
    "        messages.get()\n",
    "        display(\"Stopped\")\n",
    "    \n",
    "record_button.on_click(start_recording)\n",
    "Stop_button.on_click(stop_recording)\n",
    "\n",
    "display(record_button, Stop_button, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index': 0, 'structVersion': 2, 'name': 'MacBook Pro Microphone', 'hostApi': 0, 'maxInputChannels': 1, 'maxOutputChannels': 0, 'defaultLowInputLatency': 0.044520833333333336, 'defaultLowOutputLatency': 0.01, 'defaultHighInputLatency': 0.06452083333333333, 'defaultHighOutputLatency': 0.1, 'defaultSampleRate': 48000.0}\n",
      "{'index': 1, 'structVersion': 2, 'name': 'MacBook Pro Speakers', 'hostApi': 0, 'maxInputChannels': 0, 'maxOutputChannels': 2, 'defaultLowInputLatency': 0.01, 'defaultLowOutputLatency': 0.0090625, 'defaultHighInputLatency': 0.1, 'defaultHighOutputLatency': 0.018395833333333333, 'defaultSampleRate': 48000.0}\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "for i in range(p.get_device_count()):\n",
    "    print(p.get_device_info_by_index(i))\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHANNELS = 1 \n",
    "FRAME_RATE = 16000\n",
    "RECORD_SECONDS= 4 # every 20 second audio is going to be translated to text\n",
    "AUDIO_FORMAT = pyaudio.paInt16\n",
    "SAMPLE_SIZE = 2\n",
    "\n",
    "# Chunk defines how often we are gonna read from the microphone. \n",
    "# input = true means that we are recording from a microphone\n",
    "# frames per buffer means how often we are going to read data from our microphone\n",
    "\n",
    "\n",
    "\n",
    "def record_microphone(chunks=1024): # 1024 audio frames at the time\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=AUDIO_FORMAT, channels=CHANNELS, rate=FRAME_RATE, input=True, input_device_index = 0, frames_per_buffer=chunks)\n",
    "    \n",
    "    # This part handels the threading work, it says that as long as the stop button is not pressed, record and store the data on thread recording. then\n",
    "    # after the defined limit empty the frame list \n",
    "    # Bascilly every 20 sec we pass our recorded audio to our trancription engine and then start recording another 20 sec\n",
    "    \n",
    "    \n",
    "    # In the first iteration the frames list contains a single data items which is a chunk with 1024 frames it requires approxiametly 312 iteraions\n",
    "    # until the conditions is reached.\n",
    "    frames = []\n",
    "    while not messages.empty():\n",
    "        \n",
    "        data = stream.read(chunks)\n",
    "        frames.append(data)\n",
    "        \n",
    "        if len(frames) >= (FRAME_RATE * RECORD_SECONDS) / chunks: # if we recorded more than 20 sec of audio\n",
    "            recording.put(frames.copy())\n",
    "            frames = []\n",
    "             \n",
    "\n",
    "    # these three lines are very important and if missed could cause some problems to the audio parts of your machine\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate ()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:11:12:13:14:15\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo /Users/sina/.cache/vosk/vosk-model-en-us-0.22/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from /Users/sina/.cache/vosk/vosk-model-en-us-0.22/rnnlm/final.raw\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece\n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "from vosk import KaldiRecognizer, Model\n",
    "import time\n",
    "from transformers import pipeline\n",
    "\n",
    "model = Model(model_name=\"vosk-model-en-us-0.22\") \n",
    "rec = KaldiRecognizer(model, FRAME_RATE)\n",
    "rec.SetWords(True)\n",
    "\n",
    "output_list = []\n",
    "\n",
    "def speech_recognitions(output):\n",
    "    \n",
    "    while not messages.empty():\n",
    "        frames = recording.get()  # Fix the queue name to 'recordings'\n",
    "        rec.AcceptWaveform(b''.join(frames))\n",
    "        result = rec.Result()\n",
    "        text = json.loads(result)[\"text\"]  # Use json.loads instead of json.load\n",
    "        \n",
    "        # This part uses transformers library to live translate english to the language of choice\n",
    "        \n",
    "        src = \"en\"\n",
    "        dst = \"fr\"\n",
    "\n",
    "        task_name = f\"translation_{src}_to_{dst}\"\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{src}-{dst}\"\n",
    "\n",
    "        translator  = pipeline(task_name, model=model_name, tokenizer=model_name)\n",
    "        \n",
    "        cased = subprocess.check_output(' python3 /Users/sina/Python/Github/Python_projects/speech_recognition/vosk-recasepunc-en-0.22/recasepunc.py predict /Users/sina/Python/Github/Python_projects/speech_recognition/vosk-recasepunc-en-0.22/checkpoint', shell=True, text=True, input=text)\n",
    "        output.append_stdout(cased)\n",
    "        x = (translator(cased)[0][\"translation_text\"])\n",
    "        output.append_stdout(x)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "        \n",
    "             \n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
